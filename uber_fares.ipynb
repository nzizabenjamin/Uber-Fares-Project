{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35154248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "#pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv(\"uber.csv\")\n",
    "print(\"Original Dataset Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initial Inspection\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Cleaning\n",
    "# Drop rows with any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove rows with invalid fare amounts\n",
    "df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 1000)]\n",
    "\n",
    "# Remove rows with invalid passenger counts (1â€“6 considered valid)\n",
    "df = df[(df['passenger_count'] > 0) & (df['passenger_count'] <= 6)]\n",
    "\n",
    "# Convert datetime\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
    "df.dropna(subset=['pickup_datetime'], inplace=True)\n",
    "\n",
    "# Optional: Drop longitude/latitude rows outside NYC area (basic bounding box)\n",
    "df = df[\n",
    "    (df['pickup_longitude'] > -75) & (df['pickup_longitude'] < -72) &\n",
    "    (df['pickup_latitude'] > 40) & (df['pickup_latitude'] < 42)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f140bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Feature Engineering\n",
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "df['day'] = df['pickup_datetime'].dt.day\n",
    "df['month'] = df['pickup_datetime'].dt.month\n",
    "df['weekday'] = df['pickup_datetime'].dt.day_name()\n",
    "\n",
    "# Peak hours flag\n",
    "df['peak_hour'] = df['hour'].apply(lambda x: 'Peak' if x in [7,8,9,17,18,19] else 'Off-Peak')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Distance Calculation (if dropoff columns exist)\n",
    "if {'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'}.issubset(df.columns):\n",
    "    from geopy.distance import geodesic\n",
    "\n",
    "    def is_valid_coord(lat, lon):\n",
    "        return -90 <= lat <= 90 and -180 <= lon <= 180\n",
    "\n",
    "    def calculate_distance(row):\n",
    "        try:\n",
    "            pickup_lat = row['pickup_latitude']\n",
    "            pickup_lon = row['pickup_longitude']\n",
    "            dropoff_lat = row['dropoff_latitude']\n",
    "            dropoff_lon = row['dropoff_longitude']\n",
    "            \n",
    "            if is_valid_coord(pickup_lat, pickup_lon) and is_valid_coord(dropoff_lat, dropoff_lon):\n",
    "                pickup = (pickup_lat, pickup_lon)\n",
    "                dropoff = (dropoff_lat, dropoff_lon)\n",
    "                return geodesic(pickup, dropoff).km\n",
    "            else:\n",
    "                return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply only if dropoff columns exist\n",
    "    if {'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'}.issubset(df.columns):\n",
    "        df['distance_km'] = df.apply(calculate_distance, axis=1)\n",
    "        df.dropna(subset=['distance_km'], inplace=True)\n",
    "        df = df[df['distance_km'] > 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Descriptive Statistics & Plots\n",
    "print(\"\\nFare Amount Stats:\")\n",
    "#print(df['fare_amount'].describe())\n",
    "\n",
    "# 1. Central Tendency & Spread\n",
    "fare_stats = {\n",
    "    'Mean': df['fare_amount'].mean(),\n",
    "    'Median': df['fare_amount'].median(),\n",
    "    'Mode': df['fare_amount'].mode()[0],\n",
    "    'Standard Deviation': df['fare_amount'].std()\n",
    "}\n",
    "print(\"ðŸ”¹ Fare Amount - Central Tendency and Spread:\")\n",
    "for key, value in fare_stats.items():\n",
    "    print(f\"{key}: ${value:.2f}\")\n",
    "\n",
    "# 2. Quartiles and IQR\n",
    "Q1 = df['fare_amount'].quantile(0.25)\n",
    "Q2 = df['fare_amount'].quantile(0.50)\n",
    "Q3 = df['fare_amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "min_val = df['fare_amount'].min()\n",
    "max_val = df['fare_amount'].max()\n",
    "\n",
    "print(\"\\nðŸ”¹ Quartiles and Range:\")\n",
    "print(f\"Q1 (25th percentile): ${Q1:.2f}\")\n",
    "print(f\"Q2 (Median): ${Q2:.2f}\")\n",
    "print(f\"Q3 (75th percentile): ${Q3:.2f}\")\n",
    "print(f\"IQR (Q3 - Q1): ${IQR:.2f}\")\n",
    "print(f\"Minimum Fare: ${min_val:.2f}\")\n",
    "print(f\"Maximum Fare: ${max_val:.2f}\")\n",
    "\n",
    "# 3. Outlier Detection (Using IQR)\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['fare_amount'] < lower_bound) | (df['fare_amount'] > upper_bound)]\n",
    "\n",
    "print(f\"\\nðŸ”¹ Outlier Detection:\")\n",
    "print(f\"Lower Bound: ${lower_bound:.2f}\")\n",
    "print(f\"Upper Bound: ${upper_bound:.2f}\")\n",
    "print(f\"Number of Outliers: {outliers.shape[0]}\")\n",
    "print(f\"Outlier Fare Range: ${outliers['fare_amount'].min():.2f} to ${outliers['fare_amount'].max():.2f}\")\n",
    "\n",
    "\n",
    "# Histogram of Fare Amount\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df['fare_amount'], bins=50, kde=True, color='skyblue')\n",
    "plt.title('Fare Amount Distribution')\n",
    "plt.xlabel('Fare Amount ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fare_histogram.png\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Fare Amount\n",
    "plt.figure(figsize=(8, 3))\n",
    "sns.boxplot(x=df['fare_amount'], color='salmon')\n",
    "plt.title('Fare Amount Boxplot')\n",
    "plt.xlabel('Fare Amount ($)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fare_boxplot.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7478d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot: Fare vs Distance\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(x='distance_km', y='fare_amount', data=df, alpha=0.5)\n",
    "plt.title('Fare Amount vs. Distance Traveled')\n",
    "plt.xlabel('Distance (km)')\n",
    "plt.ylabel('Fare Amount ($)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fare_vs_distance.png\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot: Fare by Hour\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(x='hour', y='fare_amount', data=df)\n",
    "plt.title('Fare Amount vs. Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Fare Amount ($)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fare_vs_hour.png\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "numerical_cols = ['fare_amount', 'passenger_count', 'distance_km', 'hour', 'day', 'month']\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Key Variables')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "numerical_cols = ['fare_amount', 'passenger_count', 'distance_km', 'hour', 'day', 'month']\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Key Variables')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a12fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pickup_datetime is datetime\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "\n",
    "# Extract time-based features\n",
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "df['day'] = df['pickup_datetime'].dt.day\n",
    "df['month'] = df['pickup_datetime'].dt.month\n",
    "df['weekday'] = df['pickup_datetime'].dt.day_name()\n",
    "\n",
    "# Peak/Off-Peak Labeling\n",
    "def label_peak(hour):\n",
    "    if 7 <= hour <= 9 or 17 <= hour <= 19:\n",
    "        return 'Peak'\n",
    "    return 'Off-Peak'\n",
    "\n",
    "df['peak_offpeak'] = df['hour'].apply(label_peak)\n",
    "\n",
    "# Convert categorical variables into category type (Power BI can read this too)\n",
    "df['weekday'] = df['weekday'].astype('category')\n",
    "df['peak_offpeak'] = df['peak_offpeak'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f64d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7. Save Cleaned & Enhanced Dataset\n",
    "# -----------------------------\n",
    "df.to_csv(\"uber_enhanced.csv\", index=False)\n",
    "print(\"\\nCleaned and enhanced dataset saved as 'uber_enhanced.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
